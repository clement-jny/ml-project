{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Designing a virtual assistant for corporate documentation\n",
    "\n",
    "ChatGPT-like systems employ Natural Language Processing (NLP) to facilitate interactions in natural language with users, enabling intuitive access to specific information. In the context of this project, you are tasked with designing a simplified system for querying corporate documentation using both full-text and semantic search.\n",
    "\n",
    "## Objective 1 :\n",
    "\n",
    "Enable the search for documents using a short phrase, returning only the documents that match.\n",
    "\n",
    "## Objective 2 :\n",
    "\n",
    "Allow users to pose questions to their corporate documentation and receive a textual response synthesizing the found sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rules\n",
    "\n",
    "- The entire environment must be containerized using Docker.\n",
    "- Include instructions for installation and use (Readme.md).\n",
    "- Address the handling of proper nouns and Out Of Vocabulary (OOV) words in the embedding model.\n",
    "- Enable both full-text and semantic search capabilities.\n",
    "- Use models that are either locally hosted or cloud-based, but with unlimited/free access (for the validation phase, which may be intensive, and provide the access details).\n",
    "- Responses to searches must be supplemented with the sources used\n",
    "\n",
    "![image_source](./example-LLM-sources.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "For this project, we will use the Wikipedia documentation. You can download it using the following code.\n",
    "\n",
    "You are not required to index the entire dataset, but only a part of it. In this case, you will need to specify which subset you have used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6702ddc454c44c8d8313fe4db5e95556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/36.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ab3424993649c9ba1ab49653f7acc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/627M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf5a201f7614aad80fefee3a303b766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/703M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0339486ad2141f1b2a2af29aa84d496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/583M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc824099f5148569264c61916df722f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/154M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e651aea24f4dc0aad6943f02b6126e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/591M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f687f898e6c4718962f2dd9912fd4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/288M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a4ded6f7ff40179f9fcf6739a750db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/555M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc912d17324431bb7a5403753a7f6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/464M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a25389666341e8a8f7dec7c9ee8e93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/185M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807a34039a294a48abab450c5c18e574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/429M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7063be87bb747ad86795a3cc04be9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/415M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11db09069094905958ed49e16f4dbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/472M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632b71795b3b46a29927bacc7d204a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/448M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714249029f8644ac86d75cda0fe2ff5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9a741faac445a4a9c00b4ad5b9f2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting content from /home/benjamin/.cache/huggingface/datasets/downloads/f0498bb116fe7e3173f2abc8983487f3253a43f4a314af0b4091643b772417ff\n"
     ]
    }
   ],
   "source": [
    "# pip install datasets mwparserfromhell\n",
    "# see here for explaination : https://huggingface.co/datasets/wikipedia\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "load_dataset(\"wikipedia\", language=\"fr\", date=\"20231220\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Info\n",
    "\n",
    "This project is a typical enterprise use case. Whenever you hear about ChatGPT/LLM/GPT in a business context, it's almost always for performing enhanced semantic search or \"talk to my data\" on internal documentation or for a chatbot.\n",
    "\n",
    "There are software solutions that allow you to do this in a plug-and-play manner (which is not the objective of this project), such as:\n",
    "- Algolia\n",
    "- Azure Cognitive Search\n",
    "\n",
    "And there are documentation-focused software solutions that integrate LLM models:\n",
    "- Slite\n",
    "- Confluence\n",
    "- Notion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
